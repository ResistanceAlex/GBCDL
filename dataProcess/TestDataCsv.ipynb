{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import csv\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "加载csv文件函数\n",
    "\n",
    "param：\n",
    "- csv_filename: csv文件路径\n",
    "\n",
    "return:\n",
    "- image: 类别列表\n",
    "- label: 标签列表\n",
    "'''\n",
    "def loadCsv(csv_filename):\n",
    "    image, label = [], []\n",
    "    with open(csv_filename) as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            i, l = row\n",
    "            image.append(i)\n",
    "            label.append(l)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = pd.read_csv('E:/GBCDL/data/val.csv')\n",
    "img_pth = val_dataset['img_path']\n",
    "label = val_dataset['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GBCValDataset(Dataset):\n",
    "    def __init__(self, images, labels, resize):\n",
    "        \n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.resize = resize\n",
    "\n",
    "        # 数据预处理和增强\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.RandomRotation(15),\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loaders(val_csv_dir, batch_size):\n",
    "    val_dataset = pd.read_csv(val_csv_dir)\n",
    "    val_db = GBCValDataset(val_dataset['img_path'], val_dataset['label'], 224)\n",
    "    val_dataloader = DataLoader(dataset=val_db, batch_size=batch_size, shuffle=True)\n",
    "    return val_dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集长度: 3167\n",
      "总批次数: 99\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "val_csv_dir = 'E:/GBCDL/data/val.csv'\n",
    "\n",
    "val_dataloader = get_loaders(val_csv_dir, 32)\n",
    "\n",
    "# 计算DataLoader中数据的数量\n",
    "data_length = len(val_dataloader.dataset)\n",
    "        \n",
    "# 如果你想要获取DataLoader中加载的总批次数，可以使用以下代码\n",
    "num_batches = len(val_dataloader)\n",
    "        \n",
    "print(f\"数据集长度: {data_length}\")\n",
    "print(f\"总批次数: {num_batches}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集长度: 2538\n",
      "总批次数: 80\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "test_csv_dir = 'E:/GBCDL/data/test.csv'\n",
    "\n",
    "test_dataloader = get_loaders(test_csv_dir, 32)\n",
    "\n",
    "# 计算DataLoader中数据的数量\n",
    "data_length = len(test_dataloader.dataset)\n",
    "        \n",
    "# 如果你想要获取DataLoader中加载的总批次数，可以使用以下代码\n",
    "num_batches = len(test_dataloader)\n",
    "        \n",
    "print(f\"数据集长度: {data_length}\")\n",
    "print(f\"总批次数: {num_batches}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集长度: 16201\n",
      "总批次数: 507\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "train_csv_dir = 'E:/GBCDL/data/train.csv'\n",
    "\n",
    "train_dataloader = get_loaders(train_csv_dir, 32)\n",
    "\n",
    "# 计算DataLoader中数据的数量\n",
    "data_length = len(train_dataloader.dataset)\n",
    "        \n",
    "# 如果你想要获取DataLoader中加载的总批次数，可以使用以下代码\n",
    "num_batches = len(train_dataloader)\n",
    "        \n",
    "print(f\"数据集长度: {data_length}\")\n",
    "print(f\"总批次数: {num_batches}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "'''\n",
    "统计csv类别函数\n",
    "\n",
    "param：\n",
    "- csv_files: csv文件路径\n",
    "\n",
    "return:\n",
    "- label_counts: 类别总数\n",
    "'''\n",
    "def count_labels(csv_files):\n",
    "    label_counts = {}\n",
    "\n",
    "    for file_name in csv_files:\n",
    "        with open(file_name, 'r', newline='') as file:\n",
    "            reader = csv.DictReader(file)\n",
    "            for row in reader:\n",
    "                label = row['label']\n",
    "                if label in label_counts:\n",
    "                    label_counts[label] += 1\n",
    "                else:\n",
    "                    label_counts[label] = 1\n",
    "\n",
    "    return label_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Counts:\n",
      "0: 9235\n",
      "1: 8107\n",
      "2: 4564\n",
      "sum:21906\n",
      "Label %:\n",
      "0: 0.42157399799141787\n",
      "1: 0.37008125627681915\n",
      "2: 0.20834474573176298\n"
     ]
    }
   ],
   "source": [
    "csv_files = ['E:/GBCDL/data/train.csv', 'E:/GBCDL/data/test.csv', 'E:/GBCDL/data/val.csv']  \n",
    "label_counts = count_labels(csv_files)\n",
    "\n",
    "print(\"Label Counts:\")\n",
    "sum = 0\n",
    "for label, count in label_counts.items():\n",
    "    sum = sum + count\n",
    "    print(f\"{label}: {count}\")\n",
    "\n",
    "print(f\"sum:{sum}\")\n",
    "print(\"Label %:\")\n",
    "for label, count in label_counts.items():\n",
    "    print(f\"{label}: {count/sum}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
